{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22741d8c",
   "metadata": {},
   "source": [
    "# Word2Vec Experiments sur les Archives de Journaux\n",
    "\n",
    "Ce notebook explore l'utilisation de Word2Vec pour analyser les textes des journaux des années 1950-1970.\n",
    "\n",
    "## Plan\n",
    "1. Chargement et préparation des données\n",
    "2. Entraînement de modèles Word2Vec avec différents paramètres\n",
    "3. Évaluation et comparaison des modèles\n",
    "4. Analyse des relations sémantiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca9d9d",
   "metadata": {},
   "source": [
    "## 1. Installation et importation des bibliothèques\n",
    "\n",
    "Nous allons d'abord installer et importer les bibliothèques nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des bibliothèques nécessaires\n",
    "!pip install gensim nltk tqdm\n",
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e687cce",
   "metadata": {},
   "source": [
    "## 2. Chargement et préparation des données\n",
    "\n",
    "Nous allons charger les données depuis les fichiers texte préparés. Les phrases sont déjà tokenisées dans le fichier sents.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6fd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des phrases depuis sents.txt\n",
    "sentences = []\n",
    "with open('data/txt/sents.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f):\n",
    "        # Tokenization des mots de chaque phrase\n",
    "        tokens = word_tokenize(line.strip().lower())\n",
    "        if tokens:  # Ignorer les lignes vides\n",
    "            sentences.append(tokens)\n",
    "\n",
    "print(f\"Nombre total de phrases chargées : {len(sentences)}\")\n",
    "print(f\"Exemple de phrase tokenisée : {sentences[0][:30]}\")  # Afficher les 30 premiers tokens d'une phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac144014",
   "metadata": {},
   "source": [
    "## 3. Entraînement des modèles Word2Vec\n",
    "\n",
    "Nous allons entraîner plusieurs modèles Word2Vec avec différentes configurations :\n",
    "- Tailles de fenêtre contextuelles : 3, 5, et 7 mots\n",
    "- Fréquences minimales des mots : 3, 5, et 10 occurrences\n",
    "\n",
    "Pour chaque combinaison, nous entraînerons un modèle et évaluerons ses performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11744581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des paramètres à tester\n",
    "window_sizes = [3, 5, 7]\n",
    "min_counts = [3, 5, 10]\n",
    "\n",
    "# Dictionnaire pour stocker les modèles\n",
    "models = {}\n",
    "\n",
    "# Entraînement des modèles avec différentes configurations\n",
    "for window in window_sizes:\n",
    "    for min_count in min_counts:\n",
    "        print(f\"\\nEntraînement du modèle avec window={window}, min_count={min_count}\")\n",
    "        \n",
    "        model = Word2Vec(sentences=sentences,\n",
    "                        vector_size=100,  # Dimension des vecteurs\n",
    "                        window=window,    # Taille de la fenêtre contextuelle\n",
    "                        min_count=min_count,  # Fréquence minimale des mots\n",
    "                        workers=4)        # Nombre de threads pour l'entraînement\n",
    "        \n",
    "        # Sauvegarde du modèle dans le dictionnaire\n",
    "        models[f\"w{window}_mc{min_count}\"] = model\n",
    "        \n",
    "        # Affichage de quelques statistiques\n",
    "        print(f\"Vocabulaire : {len(model.wv.key_to_index)} mots\")\n",
    "        \n",
    "# Sauvegarde des modèles sur disque\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "    \n",
    "for name, model in models.items():\n",
    "    model.save(f\"models/word2vec_{name}.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d20e7",
   "metadata": {},
   "source": [
    "## 4. Évaluation et comparaison des modèles\n",
    "\n",
    "Nous allons maintenant évaluer les différents modèles en examinant les similarités entre les mots et en comparant les résultats obtenus avec différentes configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf57011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'évaluation pour un mot donné\n",
    "def evaluate_word(model, word, topn=10):\n",
    "    try:\n",
    "        similar_words = model.wv.most_similar(word, topn=topn)\n",
    "        print(f\"\\nMots les plus similaires à '{word}':\")\n",
    "        for w, score in similar_words:\n",
    "            print(f\"{w}: {score:.4f}\")\n",
    "    except KeyError:\n",
    "        print(f\"Le mot '{word}' n'est pas dans le vocabulaire du modèle\")\n",
    "\n",
    "# Liste de mots à tester\n",
    "test_words = ['président', 'france', 'paris', 'guerre', 'paix', 'europe']\n",
    "\n",
    "# Évaluation pour chaque modèle\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Modèle {name} ===\")\n",
    "    for word in test_words:\n",
    "        evaluate_word(model, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des relations sémantiques\n",
    "def test_analogy(model, word1, word2, word3, topn=5):\n",
    "    try:\n",
    "        results = model.wv.most_similar(positive=[word2, word3], negative=[word1], topn=topn)\n",
    "        print(f\"\\nAnalogies pour : {word1} est à {word2} ce que {word3} est à :\")\n",
    "        for w, score in results:\n",
    "            print(f\"{w}: {score:.4f}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Erreur: un des mots n'est pas dans le vocabulaire - {e}\")\n",
    "\n",
    "# Test de quelques analogies intéressantes\n",
    "analogies = [\n",
    "    ('paris', 'france', 'londres'),  # Paris est à France ce que Londres est à ?\n",
    "    ('homme', 'roi', 'femme'),       # Homme est à Roi ce que Femme est à ?\n",
    "    ('matin', 'jour', 'soir')        # Matin est à Jour ce que Soir est à ?\n",
    "]\n",
    "\n",
    "# Test des analogies sur le modèle avec la plus grande fenêtre et min_count=5\n",
    "model = models['w7_mc5']\n",
    "for w1, w2, w3 in analogies:\n",
    "    test_analogy(model, w1, w2, w3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tac_venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
