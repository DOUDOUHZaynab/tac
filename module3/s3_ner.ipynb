{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance d'entités nommées avec SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation est accessible ici: https://spacy.io/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fr_core_news_md in c:\\users\\sophi\\tac\\tac_venv\\lib\\site-packages (3.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "!pip install  fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple sur un corpus de test fourni par SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars',\n",
       " \"Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs\",\n",
       " \"San Francisco envisage d'interdire les robots coursiers sur les trottoirs\",\n",
       " 'Londres est une grande ville du Royaume-Uni',\n",
       " 'L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe',\n",
       " \"Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon\",\n",
       " \"La France ne devrait pas manquer d'électricité cet été, même en cas de canicule\",\n",
       " 'Nouvelles attaques de Trump contre le maire de Londres',\n",
       " 'Où es-tu ?',\n",
       " 'Qui est le président de la France ?',\n",
       " 'Où est la capitale des États-Unis ?',\n",
       " 'Quand est né Barack Obama ?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer le corpus de Spacy\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isoler la première phrase\n",
    "sent = sentences[0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter la phrase avec Spacy\n",
    "doc = nlp(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars',\n",
       " 'ents': [{'start': 0, 'end': 5, 'label': 'ORG'}],\n",
       " 'sents': [{'start': 0, 'end': 72}],\n",
       " 'tokens': [{'id': 0,\n",
       "   'start': 0,\n",
       "   'end': 5,\n",
       "   'tag': 'PROPN',\n",
       "   'pos': 'PROPN',\n",
       "   'morph': 'Gender=Masc|Number=Sing',\n",
       "   'lemma': 'Apple',\n",
       "   'dep': 'nsubj',\n",
       "   'head': 1},\n",
       "  {'id': 1,\n",
       "   'start': 6,\n",
       "   'end': 13,\n",
       "   'tag': 'VERB',\n",
       "   'pos': 'VERB',\n",
       "   'morph': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin',\n",
       "   'lemma': 'cherche',\n",
       "   'dep': 'ROOT',\n",
       "   'head': 1},\n",
       "  {'id': 2,\n",
       "   'start': 14,\n",
       "   'end': 15,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'à',\n",
       "   'dep': 'mark',\n",
       "   'head': 3},\n",
       "  {'id': 3,\n",
       "   'start': 16,\n",
       "   'end': 23,\n",
       "   'tag': 'VERB',\n",
       "   'pos': 'VERB',\n",
       "   'morph': 'VerbForm=Inf',\n",
       "   'lemma': 'acheter',\n",
       "   'dep': 'xcomp',\n",
       "   'head': 1},\n",
       "  {'id': 4,\n",
       "   'start': 24,\n",
       "   'end': 27,\n",
       "   'tag': 'DET',\n",
       "   'pos': 'DET',\n",
       "   'morph': 'Definite=Ind|Gender=Fem|Number=Sing|PronType=Art',\n",
       "   'lemma': 'un',\n",
       "   'dep': 'det',\n",
       "   'head': 5},\n",
       "  {'id': 5,\n",
       "   'start': 28,\n",
       "   'end': 33,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Fem|Number=Sing',\n",
       "   'lemma': 'start',\n",
       "   'dep': 'obj',\n",
       "   'head': 3},\n",
       "  {'id': 6,\n",
       "   'start': 33,\n",
       "   'end': 34,\n",
       "   'tag': 'PROPN',\n",
       "   'pos': 'PROPN',\n",
       "   'morph': '',\n",
       "   'lemma': '-',\n",
       "   'dep': 'obl:arg',\n",
       "   'head': 3},\n",
       "  {'id': 7,\n",
       "   'start': 34,\n",
       "   'end': 36,\n",
       "   'tag': 'X',\n",
       "   'pos': 'X',\n",
       "   'morph': '',\n",
       "   'lemma': 'up',\n",
       "   'dep': 'obl:arg',\n",
       "   'head': 3},\n",
       "  {'id': 8,\n",
       "   'start': 37,\n",
       "   'end': 45,\n",
       "   'tag': 'ADJ',\n",
       "   'pos': 'ADJ',\n",
       "   'morph': 'Gender=Fem|Number=Sing',\n",
       "   'lemma': 'anglais',\n",
       "   'dep': 'obj',\n",
       "   'head': 3},\n",
       "  {'id': 9,\n",
       "   'start': 46,\n",
       "   'end': 50,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'pour',\n",
       "   'dep': 'case',\n",
       "   'head': 11},\n",
       "  {'id': 10,\n",
       "   'start': 51,\n",
       "   'end': 52,\n",
       "   'tag': 'NUM',\n",
       "   'pos': 'NUM',\n",
       "   'morph': 'NumType=Card',\n",
       "   'lemma': '1',\n",
       "   'dep': 'nummod',\n",
       "   'head': 11},\n",
       "  {'id': 11,\n",
       "   'start': 53,\n",
       "   'end': 61,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Masc|NumType=Card|Number=Sing',\n",
       "   'lemma': 'milliard',\n",
       "   'dep': 'obl:mod',\n",
       "   'head': 3},\n",
       "  {'id': 12,\n",
       "   'start': 62,\n",
       "   'end': 64,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'de',\n",
       "   'dep': 'case',\n",
       "   'head': 13},\n",
       "  {'id': 13,\n",
       "   'start': 65,\n",
       "   'end': 72,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Masc|Number=Plur',\n",
       "   'lemma': 'dollar',\n",
       "   'dep': 'nmod',\n",
       "   'head': 11}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars' contient les entités suivantes : Apple (ORG)\n",
      "'Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs' ne contient aucune entité\n",
      "'San Francisco envisage d'interdire les robots coursiers sur les trottoirs' contient les entités suivantes : San Francisco (LOC)\n",
      "'Londres est une grande ville du Royaume-Uni' contient les entités suivantes : Londres (LOC), Royaume-Uni (LOC)\n",
      "'L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe' contient les entités suivantes : L’Italie (LOC), ArcelorMittal (ORG), Europe (LOC)\n",
      "'Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon' contient les entités suivantes : Apple (ORG), HomePod (MISC), Echo (ORG), Amazon (ORG)\n",
      "'La France ne devrait pas manquer d'électricité cet été, même en cas de canicule' contient les entités suivantes : La France (LOC)\n",
      "'Nouvelles attaques de Trump contre le maire de Londres' contient les entités suivantes : Nouvelles attaques de (MISC), Trump (PER), Londres (LOC)\n",
      "'Où es-tu ?' ne contient aucune entité\n",
      "'Qui est le président de la France ?' contient les entités suivantes : la France (LOC)\n",
      "'Où est la capitale des États-Unis ?' contient les entités suivantes : États-Unis (LOC)\n",
      "'Quand est né Barack Obama ?' contient les entités suivantes : Barack Obama (PER)\n"
     ]
    }
   ],
   "source": [
    "# Appliquer le test sur toutes les phrases\n",
    "for sent in sentences:\n",
    "    doc = nlp(sent)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append(f\"{ent.text} ({ent.label_})\")\n",
    "    if entities:\n",
    "        print(f\"'{doc.text}' contient les entités suivantes : {', '.join(entities)}\")\n",
    "    else:\n",
    "        print(f\"'{doc.text}' ne contient aucune entité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer la reconnaissance d'entités nommées sur notre corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/all.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Charger le texte\u001b[39;00m\n\u001b[32m      2\u001b[39m n=\u001b[32m1000000\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m text = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/all.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.read()[:n]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sophi\\tac\\tac_venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/all.txt'"
     ]
    }
   ],
   "source": [
    "# Charger le texte\n",
    "n=1000000\n",
    "text = open(\"../data/all.txt\", encoding='utf-8').read()[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Traiter le texte\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les entités\n",
    "people = defaultdict(int)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\" and len(ent.text) > 3:\n",
    "        people[ent.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier et imprimer\n",
    "\n",
    "sorted_people = sorted(people.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for person, freq in sorted_people[:50]:\n",
    "    print(f\"{person} apparait {freq} fois dans le corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice: essayez de lister les lieux (LOC) et les organisations (ORG) les plus mentionnées dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tac_venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
